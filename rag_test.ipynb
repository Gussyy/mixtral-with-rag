{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 901/901 [02:53<00:00,  5.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import pypdf\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-small-v2')\n",
    "\n",
    "contents = []\n",
    "# creating a pdf reader object\n",
    "\n",
    "reader = pypdf.PdfReader(r\"D:\\Download\\Mechanics of Materials 10th Edition by Russell C. Hibbeler (z-lib.org) (5).pdf\")\n",
    "for i in tqdm(range(len(reader.pages))):\n",
    "    content = reader.pages[i].extract_text()\n",
    "    for j in tokenizer.encode(content, max_length=505, padding=True,truncation=True, return_overflowing_tokens=True):\n",
    "        tok = j\n",
    "        if len(j)<10:\n",
    "            continue\n",
    "        prefix = tokenizer.encode('passage: ')[:-1]\n",
    "        prefix.extend(tok[1:])\n",
    "        passage = tokenizer.decode(prefix)\n",
    "        contents.append(passage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_pass_batch = []\n",
    "batch_size = 64\n",
    "i = batch_size\n",
    "j = 0\n",
    "while(True):\n",
    "    tok_pass = tokenizer(contents[j:i], max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    tok_pass_batch.append(tok_pass)\n",
    "    i = i + batch_size\n",
    "    j = j + batch_size\n",
    "    if i>len(contents):\n",
    "        i = len(contents)-1\n",
    "        tok_pass = tokenizer(contents[j:i], max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "        tok_pass_batch.append(tok_pass)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "question = ['query: What is shear stress',\n",
    "               'query: Why strength of matrtial important',]\n",
    "# Each input text should start with \"query: \" or \"passage: \".\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "input_texts = []\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-small-v2')\n",
    "model = AutoModel.from_pretrained('intfloat/e5-small-v2').cuda()\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(question, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "batch_dict = batch_dict.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch_dict)\n",
    "    embeddings_q = average_pool(outputs.last_hidden_state, batch_dict['attention_mask']).to('cpu')\n",
    "    batch_dict = batch_dict.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:06<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "list_embeddings_v = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(tok_pass_batch):\n",
    "        batch_dict = i\n",
    "        batch_dict = batch_dict.to('cuda')\n",
    "        outputs = model(**batch_dict)\n",
    "        embeddings_v = average_pool(outputs.last_hidden_state, batch_dict['attention_mask']).to('cpu')\n",
    "        del outputs\n",
    "        del batch_dict\n",
    "        list_embeddings_v.append(embeddings_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]C:\\Users\\prath\\AppData\\Local\\Temp\\ipykernel_18844\\1208354743.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  fn_scores = F.softmax(scores)\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j in tqdm(range(len(list_embeddings_v))):\n",
    "    # normalize embeddings\n",
    "    embeddings_q = F.normalize(embeddings_q, p=2, dim=1)\n",
    "    embeddings_v = F.normalize(list_embeddings_v[j], p=2, dim=1)\n",
    "    scores = (embeddings_q @ embeddings_v.T) * 100\n",
    "    fn_scores = F.softmax(scores)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1231e-05, 3.5656e-05, 9.8224e-07, 3.9608e-06, 2.7174e-05, 2.9820e-03,\n",
       "         1.7511e-03, 9.0427e-05, 1.2992e-04, 7.7315e-05, 4.4685e-05, 2.8075e-03,\n",
       "         2.6352e-02, 5.6908e-04, 4.2344e-03, 2.7006e-01, 1.0014e-02, 6.5788e-04,\n",
       "         1.1644e-03, 1.3069e-04, 3.0106e-02, 1.0383e-03, 1.8039e-04, 5.0195e-05,\n",
       "         1.2938e-03, 3.0632e-05, 5.7133e-03, 4.5089e-07, 3.6721e-06, 3.1355e-03,\n",
       "         3.7485e-04, 1.3265e-03, 1.2359e-04, 6.4495e-04, 2.5481e-04, 1.5148e-02,\n",
       "         1.3561e-01, 7.5287e-07, 2.7957e-03, 8.3291e-04, 8.1535e-03, 9.6101e-04,\n",
       "         4.6715e-03, 1.6543e-03, 8.4937e-03, 2.4322e-03, 1.3805e-01, 7.0337e-08,\n",
       "         3.0354e-02, 3.9482e-05, 6.9559e-02, 4.4839e-02, 6.1094e-02, 1.9533e-02,\n",
       "         8.3044e-03, 1.1173e-02, 1.3067e-02, 6.3372e-03, 8.6362e-03, 1.4141e-02,\n",
       "         2.2888e-03, 1.2027e-06, 6.6361e-03, 1.9759e-02],\n",
       "        [5.4593e-04, 2.3580e-03, 1.6316e-04, 1.6104e-03, 1.1433e-02, 2.2643e-03,\n",
       "         1.6271e-02, 1.8059e-02, 1.1382e-02, 2.1113e-02, 8.0018e-04, 1.0165e-01,\n",
       "         6.7835e-03, 1.3327e-02, 3.5015e-03, 3.5355e-02, 1.8127e-01, 3.7755e-02,\n",
       "         1.5052e-02, 1.7259e-02, 5.6760e-02, 5.8707e-02, 2.9553e-02, 5.8522e-03,\n",
       "         1.0469e-02, 4.3542e-03, 9.1072e-03, 4.0273e-05, 1.2311e-03, 3.2915e-03,\n",
       "         1.9623e-02, 1.1010e-02, 9.4903e-03, 8.2002e-03, 5.0908e-03, 3.4728e-02,\n",
       "         2.8051e-02, 6.3872e-05, 8.6242e-03, 5.6392e-03, 4.7044e-03, 3.1979e-03,\n",
       "         1.9611e-02, 4.9401e-03, 9.8843e-03, 1.6811e-02, 6.2323e-03, 6.0017e-06,\n",
       "         6.5153e-03, 1.3679e-03, 1.2556e-02, 8.1471e-03, 1.1724e-02, 3.5412e-03,\n",
       "         4.3858e-03, 3.8004e-03, 1.7012e-02, 4.0350e-03, 4.8957e-03, 7.4668e-04,\n",
       "         5.7862e-03, 5.3862e-05, 2.8128e-03, 3.9396e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
